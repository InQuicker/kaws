#cloud-config

coreos:
  etcd2:
    proxy: on
    initial_cluster: etcd_01=http://10.0.1.4:2380,etcd_02=http://10.0.1.5:2380,etcd_03=http://10.0.1.6:2380
    listen-client-urls: http://127.0.0.1:2379
  flannel:
    etcd_endpoints: http://127.0.0.1:2379
    interface: $private_ipv4
  fleet:
    etcd-servers: http://127.0.0.1:2379
    metadata: etcd=proxy,kubernetes=node
    public-ip: $private_ipv4
  units:
    - name: etcd2.service
      command: start
    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            AFter=flanneld.service
        - name: 50-opts.conf
          content: |
            [Service]
            Environment=DOCKER_OPTS='--log-driver=journald'
    - name: flanneld.service
      command: start
    - name: fleet.service
      command: start
    - name: kaws-agent.service
      command: start
      content: |
        [Unit]
        Description=kaws agent
        Requires=etcd2.service
        After=etcd2.service
        [Service]
        TimeoutStartSec=0
        ExecStartPre=/bin/bash -c 'until curl -sf "http://127.0.0.1:2379/v2/keys/kaws"; do sleep 5; done'
        ExecStart=/usr/bin/rkt --insecure-options image run \
          --volume etc-kubernetes,kind=host,source=/etc/kubernetes \
          --volume etc-resolve-conf,kind=host,source=/etc/resolv.conf \
          --mount volume=etc-kubernetes,target=/etc/kubernetes \
          --mount volume=etc-resolve-conf,target=/etc/resolv.conf \
          --stage1-from-dir stage1-fly.aci \
          docker://inquicker/kaws-agent \
          -- \
          run \
          --region ${region} \
          --role node
        KillMode=mixed
        Restart=always
        [Install]
        WantedBy=multi-user.target
    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Description=Kubernetes Kubelet
        Requires=kaws-agent.service
        After=kaws-agent.service
        [Service]
        Environment=KUBELET_VERSION=v${version}
        Environment=KUBELET_ACI=docker://gcr.io/google_containers/hyperkube
        Environment="RKT_OPTS=--volume resolv,kind=host,source=/etc/resolv.conf --mount volume=resolv,target=/etc/resolv.conf --insecure-options=image"
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --allow-privileged=true \
          --api-servers=https://${master_ip}:443 \
          --cloud-provider=aws \
          --cluster-dns=10.3.0.10 \
          --cluster-domain=cluster.local \
          --hostname-override=$private_ipv4 \
          --kubeconfig=/etc/kubernetes/node-kubeconfig.yml \
          --logtostderr=true \
          --pod-manifest-path=/etc/kubernetes/manifests \
          --register-node=true \
          --tls-cert-file=/etc/kubernetes/ssl/node.pem \
          --tls-private-key-file=/etc/kubernetes/ssl/node-key.pem
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
    - name: restart-kube-components@.path
      content: |
        [Unit]
        Description=Restart Kubernetes system components if %f changes
        [Path]
        PathChanged=%f
        Unit=restart-kube-components.service
    - name: restart-kube-components@etc-kubernetes-ssl-ca.pem.path
      enable: true
      command: start
    - name: restart-kube-components@etc-kubernetes-ssl-node.pem.path
      enable: true
      command: start
    - name: restart-kube-components@etc-kubernetes-ssl-node\x2dkey.pem.path
      enable: true
      command: start
    - name: restart-kube-components.service
      content: |
        [Unit]
        Description=Restart Kubernetes system components
        [Service]
        Type=oneshot
        ExecStart=/opt/bin/restart-kube-components.sh
write_files:
  - path: /opt/bin/restart-kube-components.sh
    permissions: "0755"
    owner: root
    content: |
      #!/usr/bin/bash -ex
      docker kill $(docker ps -q -f label=io.kubernetes.container.name=kube-proxy)
      systemctl restart kubelet
  - path: /etc/kubernetes/manifests/kube-proxy.yml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: gcr.io/google_containers/hyperkube:v${version}
          command:
          - /hyperkube
          - proxy
          - --healthz-bind-address=0.0.0.0
          - --kubeconfig=/etc/kubernetes/node-kubeconfig.yml
          - --master=https://${master_ip}:443
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /etc/ssl/certs
              name: "ssl-certs"
            - mountPath: /etc/kubernetes/node-kubeconfig.yml
              name: "kubeconfig"
              readOnly: true
            - mountPath: /etc/kubernetes/ssl
              name: "etc-kube-ssl"
              readOnly: true
        volumes:
          - name: "ssl-certs"
            hostPath:
              path: "/usr/share/ca-certificates"
          - name: "kubeconfig"
            hostPath:
              path: "/etc/kubernetes/node-kubeconfig.yml"
          - name: "etc-kube-ssl"
            hostPath:
              path: "/etc/kubernetes/ssl"
  - path: /etc/kubernetes/node-kubeconfig.yml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
        - name: local
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
      contexts:
        - context:
            cluster: local
            user: node
          name: node-context
      current-context: node-context
      users:
        - name: node
          user:
            client-certificate: /etc/kubernetes/ssl/node.pem
            client-key: /etc/kubernetes/ssl/node-key.pem
  - path: /etc/kubernetes/ssl/ca.pem
    permissions: "0644"
    owner: "root"
    content: ""
  - path: /etc/kubernetes/ssl/node.pem
    permissions: "0644"
    owner: "root"
    content: ""
  - path: /etc/kubernetes/ssl/node-key.pem
    permissions: "0600"
    owner: "root"
    content: ""
